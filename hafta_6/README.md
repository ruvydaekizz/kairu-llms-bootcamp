# Hafta 6: Ä°leri DÃ¼zey Model Fine-tuning ve KiÅŸiselleÅŸtirme

Bu hafta, derin Ã¶ÄŸrenme modellerini verimli bir ÅŸekilde fine-tune etme ve kiÅŸiselleÅŸtirme konularÄ±nÄ± ele alacaÄŸÄ±z.

## ğŸ“š Konular

### 1. PEFT (Parameter Efficient Fine-Tuning)
- LoRA (Low-Rank Adaptation) nedir ve nasÄ±l Ã§alÄ±ÅŸÄ±r?
- QLoRA ile bellek optimizasyonu
- Adapter katmanlarÄ±
- PEFT ile model boyutunu kÃ¼Ã§Ã¼k tutma

### 2. Datasets + Trainer KullanÄ±mÄ±
- Hugging Face Datasets kÃ¼tÃ¼phanesi
- Veri Ã¶n iÅŸleme ve tokenization
- Trainer sÄ±nÄ±fÄ± ile model eÄŸitimi
- TrainingArguments konfigÃ¼rasyonu

### 3. Inference ve KiÅŸiselleÅŸtirilmiÅŸ Model
- Fine-tune edilmiÅŸ modeli kullanma
- Inference optimizasyonu
- Model deployment stratejileri
- KiÅŸiselleÅŸtirilmiÅŸ Ã§Ä±ktÄ±lar Ã¼retme

## ğŸ›  Pratik Uygulamalar

Her konu iÃ§in hands-on Ã¶rnekler ve kod snippet'leri iÃ§erir.

## ğŸ“‹ Gereksinimler

```bash
pip install transformers datasets peft accelerate bitsandbytes
```

## ğŸ¯ Ã–ÄŸrenme Hedefleri

Bu hafta sonunda:
- PEFT teknikleri ile verimli fine-tuning yapabileceksiniz
- Datasets ve Trainer kullanarak model eÄŸitimi gerÃ§ekleÅŸtirebileceksiniz
- Kendi modelinizi inference iÃ§in kullanabileceksiniz