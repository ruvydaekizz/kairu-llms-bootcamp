"""
Retrieval-Augmented Generation (RAG) Sistemi
===========================================

Bu kod basit bir RAG sistemini gÃ¶sterir:
1. Belge veri tabanÄ± oluÅŸturma
2. Sorgu embedding'i Ã§Ä±karma  
3. En yakÄ±n belgeyi bulma (retrieval)
4. LLM ile prompt oluÅŸturma ve yanÄ±t alma

RAG SÃ¼reci:
Query â†’ Embedding â†’ Similarity Search â†’ Document Retrieval â†’ Prompt + Context â†’ LLM â†’ Response

Gerekli KÃ¼tÃ¼phaneler:
pip install sentence-transformers openai anthropic numpy python-dotenv
"""

import numpy as np
import os
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from typing import List, Dict, Tuple
import json
from dotenv import load_dotenv

# API anahtarlarÄ± iÃ§in
load_dotenv()

# LLM seÃ§imi iÃ§in import'lar
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

print("ğŸ¤– RAG (Retrieval-Augmented Generation) Sistemi")
print("="*60)

# AdÄ±m 1: Belge Veri TabanÄ± OluÅŸturma
print("\nğŸ“š 1. Belge Veri TabanÄ± OluÅŸturma")
print("-" * 40)

# Ã–rnek belge koleksiyonu
documents = [
    {
        "id": "doc_1",
        "title": "Python Programlama",
        "content": """Python, yÃ¼ksek seviyeli, yorumlamalÄ± bir programlama dilidir. 
        1991 yÄ±lÄ±nda Guido van Rossum tarafÄ±ndan geliÅŸtirilmiÅŸtir. Python'un sÃ¶zdizimi 
        oldukÃ§a basit ve okunabilirdir. Web geliÅŸtirme, veri analizi, yapay zeka ve 
        bilimsel hesaplamalar iÃ§in yaygÄ±n olarak kullanÄ±lÄ±r. Django ve Flask gibi 
        popÃ¼ler web framework'leri vardÄ±r.""",
        "category": "Programlama"
    },
    {
        "id": "doc_2", 
        "title": "Yapay Zeka ve Machine Learning",
        "content": """Yapay zeka (AI), makinelerin insan benzeri zeka gerektiren gÃ¶revleri 
        yerine getirmesi anlamÄ±na gelir. Machine learning, AI'nin bir alt dalÄ±dÄ±r ve 
        makinelerin veriden Ã¶ÄŸrenmesini saÄŸlar. TensorFlow, PyTorch ve Scikit-learn 
        gibi kÃ¼tÃ¼phaneler ML geliÅŸtirme iÃ§in kullanÄ±lÄ±r. Supervised learning, 
        unsupervised learning ve reinforcement learning temel ML tÃ¼rleridir.""",
        "category": "Yapay Zeka"
    },
    {
        "id": "doc_3",
        "title": "Veri Bilimi ve Analitik",
        "content": """Veri bilimi, bÃ¼yÃ¼k veri setlerinden anlamlÄ± bilgiler Ã§Ä±karma sanatÄ±dÄ±r. 
        Pandas, NumPy ve Matplotlib gibi Python kÃ¼tÃ¼phaneleri veri manipÃ¼lasyonu ve 
        gÃ¶rselleÅŸtirme iÃ§in kullanÄ±lÄ±r. Veri temizleme, keÅŸif analizi, istatistiksel 
        modelleme ve makine Ã¶ÄŸrenmesi veri biliminin temel bileÅŸenleridir. 
        Ä°ÅŸ zekasÄ± ve karar verme sÃ¼reÃ§lerinde kritik role sahiptir.""",
        "category": "Veri Bilimi"
    },
    {
        "id": "doc_4",
        "title": "Web GeliÅŸtirme",
        "content": """Web geliÅŸtirme, internet iÃ§in web siteleri ve uygulamalarÄ± oluÅŸturma 
        sÃ¼recidir. Frontend geliÅŸtirme HTML, CSS ve JavaScript kullanÄ±r. Backend 
        geliÅŸtirme iÃ§in Python (Django, Flask), JavaScript (Node.js) veya diÄŸer 
        diller kullanÄ±labilir. Responsive tasarÄ±m, API geliÅŸtirme ve veritabanÄ± 
        yÃ¶netimi modern web geliÅŸtirmenin temel konularÄ±dÄ±r.""",
        "category": "Web GeliÅŸtirme"
    },
    {
        "id": "doc_5",
        "title": "VeritabanÄ± YÃ¶netimi",
        "content": """VeritabanÄ± yÃ¶netim sistemleri (DBMS), verilerin organize edilmesi, 
        saklanmasÄ± ve eriÅŸimi iÃ§in kullanÄ±lÄ±r. SQL (Structured Query Language) 
        iliÅŸkisel veritabanlarÄ± iÃ§in standart dildir. PostgreSQL, MySQL ve SQLite 
        popÃ¼ler iliÅŸkisel veritabanlarÄ±dÄ±r. NoSQL veritabanlarÄ± (MongoDB, Redis) 
        esnek veri modelleri sunar. ACID Ã¶zellikleri veri tutarlÄ±lÄ±ÄŸÄ±nÄ± saÄŸlar.""",
        "category": "VeritabanÄ±"
    }
]

print(f"âœ… {len(documents)} belge yÃ¼klendi:")
for doc in documents:
    print(f"   ğŸ“„ {doc['id']}: {doc['title']} ({doc['category']})")

# AdÄ±m 2: Embedding Model YÃ¼kleme ve Belge Embedding'leri
print("\nğŸ§  2. Embedding Model YÃ¼kleme")
print("-" * 40)

# Sentence transformer model yÃ¼kle
model = SentenceTransformer('all-MiniLM-L6-v2')
print(f"âœ… Model yÃ¼klendi: {model.get_sentence_embedding_dimension()} boyutlu embedding")

# Belge iÃ§eriklerini embedding'e Ã§evir
print("\nğŸ”„ Belge embedding'leri oluÅŸturuluyor...")
document_texts = [doc['content'] for doc in documents]
document_embeddings = model.encode(document_texts)

print(f"âœ… {len(document_embeddings)} belge embedding'i oluÅŸturuldu")
print(f"ğŸ“Š Embedding ÅŸekli: {document_embeddings.shape}")

# AdÄ±m 3: RAG Pipeline FonksiyonlarÄ±
print("\nâš™ï¸  3. RAG Pipeline FonksiyonlarÄ±")
print("-" * 40)

def retrieve_documents(query: str, top_k: int = 1) -> List[Tuple[Dict, float]]:
    """
    Sorgu iÃ§in en yakÄ±n belgeleri bulur
    
    Args:
        query: Arama sorgusu
        top_k: KaÃ§ belge dÃ¶ndÃ¼rÃ¼lecek
    
    Returns:
        (belge, benzerlik_skoru) tuple'larÄ± listesi
    """
    print(f"ğŸ” Sorgu: '{query}'")
    
    # Sorgu embedding'ini Ã§Ä±kar
    query_embedding = model.encode([query])
    print(f"ğŸ“Š Sorgu embedding boyutu: {query_embedding.shape}")
    
    # Cosine similarity hesapla
    similarities = cosine_similarity(query_embedding, document_embeddings)[0]
    print(f"ğŸ’¯ Benzerlik skorlarÄ± hesaplandÄ±: {len(similarities)} belge")
    
    # En yÃ¼ksek skorlarÄ± bul
    top_indices = np.argsort(similarities)[::-1][:top_k]
    
    results = []
    print(f"\nğŸ¯ En yakÄ±n {top_k} belge:")
    for i, idx in enumerate(top_indices):
        doc = documents[idx]
        score = similarities[idx]
        results.append((doc, score))
        print(f"   {i+1}. {doc['title']} (Skor: {score:.4f})")
    
    return results

def create_rag_prompt(query: str, context_docs: List[Dict]) -> str:
    """
    RAG iÃ§in prompt oluÅŸturur
    
    Args:
        query: KullanÄ±cÄ± sorusu
        context_docs: BaÄŸlam belgeleri
    
    Returns:
        OluÅŸturulan prompt
    """
    context_text = "\n\n".join([
        f"Belge {i+1} - {doc['title']}:\n{doc['content']}"
        for i, doc in enumerate(context_docs)
    ])
    
    prompt = f"""AÅŸaÄŸÄ±daki baÄŸlam bilgilerini kullanarak soruyu yanÄ±tla. Sadece verilen baÄŸlamda yer alan bilgileri kullan.

BAÄLAM:
{context_text}

SORU: {query}

YANIT:"""
    
    return prompt

def answer_with_openai(prompt: str) -> str:
    """OpenAI ile yanÄ±t Ã¼ret"""
    if not OPENAI_AVAILABLE:
        return "âŒ OpenAI kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. 'pip install openai' komutu ile yÃ¼kleyin."
    
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        return "âŒ OPENAI_API_KEY environment variable bulunamadÄ±. .env dosyasÄ±na ekleyin."
    
    try:
        # OpenAI client'Ä± doÄŸru ÅŸekilde baÅŸlat
        client = openai.OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sen yardÄ±mcÄ± bir AI asistanÄ±sÄ±n. Verilen baÄŸlam bilgilerini kullanarak sorularÄ± yanÄ±tla."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.3,
            top_p=1.0
        )
        
        return response.choices[0].message.content.strip()
        
    except openai.AuthenticationError:
        return "âŒ OpenAI API anahtarÄ± geÃ§ersiz. LÃ¼tfen doÄŸru API anahtarÄ±nÄ± .env dosyasÄ±na ekleyin."
    except openai.RateLimitError:
        return "âŒ OpenAI API rate limit aÅŸÄ±ldÄ±. LÃ¼tfen daha sonra tekrar deneyin."
    except openai.APIConnectionError:
        return "âŒ OpenAI API'ye baÄŸlanÄ±lamadÄ±. Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin."
    except Exception as e:
        return f"âŒ OpenAI API hatasÄ±: {str(e)}"


def rag_pipeline(query: str, llm_provider: str = "mock") -> Dict:
    """
    Tam RAG pipeline'Ä±
    
    Args:
        query: KullanÄ±cÄ± sorusu
        llm_provider: "openai" veya "mock"
    
    Returns:
        RAG sonuÃ§larÄ±
    """
    print(f"\nğŸš€ RAG Pipeline BaÅŸlatÄ±lÄ±yor...")
    print(f"ğŸ”§ LLM Provider: {llm_provider}")
    
    # 1. Retrieval - En yakÄ±n belgeyi bul
    print(f"\nğŸ“– ADIM 1: RETRIEVAL")
    retrieved_docs = retrieve_documents(query, top_k=2)
    context_docs = [doc for doc, score in retrieved_docs]
    
    # 2. Prompt oluÅŸturma
    print(f"\nâœï¸  ADIM 2: PROMPT OLUÅTURMA")
    prompt = create_rag_prompt(query, context_docs)
    print(f"ğŸ“ Prompt uzunluÄŸu: {len(prompt)} karakter")
    
    # 3. LLM ile yanÄ±t alma
    print(f"\nğŸ¤– ADIM 3: LLM YANITI")
    if llm_provider == "openai":
        response = answer_with_openai(prompt)
    else:
        # Mock yanÄ±t
        response = f"""Bu bir mock yanÄ±ttÄ±r. GerÃ§ek RAG sistemi ÅŸu adÄ±mlarÄ± tamamladÄ±:

1. âœ… Sorgu embedding'i oluÅŸturuldu
2. âœ… En yakÄ±n belgeler bulundu:
   - {context_docs[0]['title']} (Skor: {retrieved_docs[0][1]:.4f})
   - {context_docs[1]['title']} (Skor: {retrieved_docs[1][1]:.4f})
3. âœ… Prompt oluÅŸturuldu ({len(prompt)} karakter)
4. ğŸ”„ LLM yanÄ±tÄ± bekleniyor...

GerÃ§ek LLM kullanmak iÃ§in API anahtarÄ±nÄ±zÄ± .env dosyasÄ±na ekleyin:
- OpenAI: OPENAI_API_KEY=sk-your-key-here"""
    
    return {
        'query': query,
        'retrieved_docs': retrieved_docs,
        'prompt': prompt,
        'response': response,
        'llm_provider': llm_provider
    }

# AdÄ±m 4: RAG Sistemini Test Etme
print("\nğŸ§ª 4. RAG Sistemini Test Etme")
print("-" * 40)

# Test sorgularÄ±
test_queries = [
    "Python nedir ve ne iÃ§in kullanÄ±lÄ±r?",
    "Machine learning tÃ¼rleri nelerdir?",
    "Veri bilimi iÃ§in hangi Python kÃ¼tÃ¼phaneleri kullanÄ±lÄ±r?",
    "Web geliÅŸtirmede frontend ve backend arasÄ±ndaki fark nedir?",
    "SQL nedir?"
]

print(f"ğŸ“‹ {len(test_queries)} test sorusu hazÄ±rlandÄ±:")
for i, query in enumerate(test_queries, 1):
    print(f"   {i}. {query}")

# Ä°lk soruyu detaylÄ± test et
print(f"\nğŸ” DETAYLI TEST - Ä°lk Sorgu")
print("="*50)

test_query = test_queries[0]
result = rag_pipeline(test_query, llm_provider="mock")

print(f"\nğŸ“Š RAG SONUÃ‡LARI:")
print(f"ğŸ”¤ Sorgu: {result['query']}")
print(f"\nğŸ“š Bulunan Belgeler:")
for i, (doc, score) in enumerate(result['retrieved_docs'], 1):
    print(f"   {i}. {doc['title']} - Skor: {score:.4f}")
    print(f"      Kategori: {doc['category']}")
    print(f"      Ä°Ã§erik: {doc['content'][:100]}...")

print(f"\nğŸ“ OluÅŸturulan Prompt (ilk 200 karakter):")
print(f"'{result['prompt'][:200]}...'")

print(f"\nğŸ¤– LLM YanÄ±tÄ±:")
print(result['response'])

# AdÄ±m 5: TÃ¼m sorgularÄ± hÄ±zlÄ± test
print(f"\nâš¡ 5. HÄ±zlÄ± Test - TÃ¼m Sorgular")
print("-" * 40)

for i, query in enumerate(test_queries, 1):
    print(f"\nğŸ“‹ Test {i}: {query}")
    retrieved = retrieve_documents(query, top_k=1)
    best_doc, score = retrieved[0]
    print(f"   ğŸ¯ En iyi eÅŸleÅŸme: {best_doc['title']} (Skor: {score:.4f})")

# AdÄ±m 6: RAG Sistem Metrikleri
print(f"\nğŸ“ˆ 6. RAG Sistem Metrikleri")
print("-" * 40)

# Embedding kalitesi analizi
all_similarities = []
for query in test_queries:
    query_embedding = model.encode([query])
    similarities = cosine_similarity(query_embedding, document_embeddings)[0]
    all_similarities.extend(similarities)

avg_similarity = np.mean(all_similarities)
max_similarity = np.max(all_similarities)
min_similarity = np.min(all_similarities)

print(f"ğŸ¯ Embedding PerformansÄ±:")
print(f"   Ortalama benzerlik: {avg_similarity:.4f}")
print(f"   Maksimum benzerlik: {max_similarity:.4f}")
print(f"   Minimum benzerlik: {min_similarity:.4f}")

print(f"\nğŸ”§ Sistem Ã–zellikleri:")
print(f"   ğŸ“š Toplam belge sayÄ±sÄ±: {len(documents)}")
print(f"   ğŸ§  Embedding boyutu: {document_embeddings.shape[1]}")
print(f"   ğŸ“Š Model: {model.get_sentence_embedding_dimension()}D sentence-transformer")

# AdÄ±m 7: RAG Ä°yileÅŸtirme Ã–nerileri
print(f"\nğŸ’¡ 7. RAG Sistem Ä°yileÅŸtirme Ã–nerileri")
print("-" * 40)

improvement_tips = """
ğŸš€ PERFORMANS Ä°YÄ°LEÅTÄ°RMELERÄ°:

1. ğŸ“š Veri Kalitesi:
   â€¢ Belgeleri daha kÃ¼Ã§Ã¼k chunk'lara bÃ¶l
   â€¢ Metadata ekle (kategori, tarih, kaynak)
   â€¢ Overlapping chunk'lar kullan

2. ğŸ” Retrieval Ä°yileÅŸtirme:
   â€¢ Hybrid search (semantic + keyword)
   â€¢ Re-ranking modelleri kullan
   â€¢ Query expansion uygula

3. ğŸ¤– LLM Optimizasyonu:
   â€¢ Prompt engineering
   â€¢ Few-shot examples ekle
   â€¢ Response validation

4. ğŸ“Š DeÄŸerlendirme:
   â€¢ BLEU, ROUGE skorlarÄ±
   â€¢ Human evaluation
   â€¢ A/B testing

5. ğŸ—ï¸ Mimari Ä°yileÅŸtirmeler:
   â€¢ Vector database kullan (Pinecone, Weaviate)
   â€¢ Caching stratejileri
   â€¢ Async processing
"""

print(improvement_tips)

print(f"\nâœ… RAG sistemi demonstrasyonu tamamlandÄ±!")

print(f"ğŸ“„ .env dosyanÄ±zda OPENAI_API_KEY deÄŸiÅŸkenini ayarlayarak gerÃ§ek LLM kullanabilirsiniz")