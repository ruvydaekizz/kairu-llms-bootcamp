"""
Streamlit ile Frontend UygulamasÄ±
LLM tabanlÄ± chatbot ve Ã§eÅŸitli uygulamalar iÃ§in Streamlit arayÃ¼zÃ¼
"""

import streamlit as st
from openai import OpenAI
import os
from dotenv import load_dotenv
import time
import pandas as pd
import plotly.express as px

# Environment variables yÃ¼kle
load_dotenv()

# OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ============================================================================
# SAYFA YAPILANDIRMASI
# ============================================================================

st.set_page_config(
    page_title="LLM Uygulama Demo",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# SIDEBAR YAPILANDIRMASI
# ============================================================================

with st.sidebar:
    st.title("âš™ï¸ Ayarlar")
    
    # Model seÃ§imi
    model_choice = st.selectbox(
        "Model SeÃ§in:",
        ["gpt-3.5-turbo", "gpt-4"],
        index=0
    )
    
    # Temperature ayarÄ±
    temperature = st.slider(
        "Temperature (YaratÄ±cÄ±lÄ±k):",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1
    )
    
    # Max tokens ayarÄ±
    max_tokens = st.slider(
        "Max Tokens (Maksimum uzunluk):",
        min_value=50,
        max_value=500,
        value=150,
        step=50
    )
    
    st.divider()
    
    # API Key kontrolÃ¼
    if not os.getenv("OPENAI_API_KEY"):
        st.error("âš ï¸ API Key bulunamadÄ±! `.env` dosyasÄ±nÄ± kontrol edin.")
    else:
        st.success("âœ… API Key yÃ¼klendi")
    
    st.divider()
    
    # Temizle butonu
    if st.button("ğŸ—‘ï¸ TÃ¼m GeÃ§miÅŸi Temizle"):
        st.session_state.messages = []
        st.rerun()

# ============================================================================
# SESSION STATE YÃ–NETÄ°MÄ°
# ============================================================================

if "messages" not in st.session_state:
    st.session_state.messages = []

if "text_summary" not in st.session_state:
    st.session_state.text_summary = ""

if "translation_result" not in st.session_state:
    st.session_state.translation_result = ""

# ============================================================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================================================

def get_openai_response(prompt, system_prompt="Sen yardÄ±mcÄ± bir asistansÄ±n.", model="gpt-3.5-turbo"):
    """
    OpenAI API'den yanÄ±t al
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"


def stream_openai_response(prompt, system_prompt="Sen yardÄ±mcÄ± bir asistansÄ±n.", model="gpt-3.5-turbo"):
    """
    OpenAI API'den streaming yanÄ±t al
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            stream=True,
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        full_response = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                yield full_response
    except Exception as e:
        yield f"Hata oluÅŸtu: {str(e)}"


# ============================================================================
# ANA SAYFA
# ============================================================================

st.title("ğŸ¤– LLM TabanlÄ± Uygulama Ã–rnekleri")
st.markdown("Bu uygulama Streamlit kullanarak Ã§eÅŸitli LLM uygulamalarÄ±nÄ± gÃ¶sterir.")

# Tab yapÄ±sÄ±
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ’¬ Chatbot",
    "ğŸŒŠ Streaming Chatbot",
    "ğŸ“ Metin Ä°ÅŸleme",
    "ğŸ’» Kod AÃ§Ä±klama",
    "ğŸ“Š Veri GÃ¶rselleÅŸtirme"
])

# ============================================================================
# TAB 1: Basit Chatbot
# ============================================================================

with tab1:
    st.header("ğŸ’¬ Basit Chatbot")
    st.markdown("### Basit chatbot arayÃ¼zÃ¼")
    
    # Mesaj geÃ§miÅŸini gÃ¶ster
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Yeni mesaj input
    if prompt := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n..."):
        # KullanÄ±cÄ± mesajÄ±nÄ± ekle
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Bot yanÄ±tÄ±nÄ± al ve gÃ¶ster
        with st.chat_message("assistant"):
            response = get_openai_response(prompt, model=model_choice)
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

# ============================================================================
# TAB 2: Streaming Chatbot
# ============================================================================

with tab2:
    st.header("ğŸŒŠ Streaming Chatbot")
    st.markdown("### Streaming output ile chatbot")
    
    # Streaming mesaj geÃ§miÅŸi
    if "streaming_messages" not in st.session_state:
        st.session_state.streaming_messages = []
    
    for message in st.session_state.streaming_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Yeni mesaj input
    if streaming_prompt := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n... (Streaming)"):
        # KullanÄ±cÄ± mesajÄ±nÄ± ekle
        st.session_state.streaming_messages.append({"role": "user", "content": streaming_prompt})
        with st.chat_message("user"):
            st.markdown(streaming_prompt)
        
        # Bot streaming yanÄ±tÄ±nÄ± al ve gÃ¶ster
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            for chunk in stream_openai_response(streaming_prompt, model=model_choice):
                full_response = chunk
                message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            st.session_state.streaming_messages.append({"role": "assistant", "content": full_response})
    
    # Temizle butonu
    if st.button("ğŸ—‘ï¸ Streaming GeÃ§miÅŸini Temizle"):
        st.session_state.streaming_messages = []
        st.rerun()

# ============================================================================
# TAB 3: Metin Ä°ÅŸleme
# ============================================================================

with tab3:
    st.header("ğŸ“ Metin Ä°ÅŸleme")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“„ Metin Ã–zetleme")
        text_input = st.text_area(
            "Ã–zetlemek istediÄŸiniz metni yazÄ±n:",
            height=200,
            placeholder="Metninizi buraya yazÄ±n..."
        )
        
        if st.button("Ã–zetle", type="primary"):
            if text_input:
                with st.spinner("Ã–zetleme yapÄ±lÄ±yor..."):
                    summary = get_openai_response(
                        f"Bu metni Ã¶zetle:\n\n{text_input}",
                        "Sen bir metin Ã¶zetleme uzmanÄ±sÄ±n. Verilen metni kÄ±sa ve Ã¶z ÅŸekilde Ã¶zetle.",
                        model=model_choice
                    )
                    st.session_state.text_summary = summary
                    st.success("Ã–zetleme tamamlandÄ±!")
        
        if st.session_state.text_summary:
            st.text_area("Ã–zet:", value=st.session_state.text_summary, height=150)
    
    with col2:
        st.subheader("ğŸŒ Metin Ã‡eviri")
        translate_input = st.text_area(
            "Ã‡evirmek istediÄŸiniz metni yazÄ±n:",
            height=150,
            placeholder="Ã‡evrilecek metni buraya yazÄ±n..."
        )
        
        target_language = st.selectbox(
            "Hedef Dil:",
            ["Ä°ngilizce", "FransÄ±zca", "Almanca", "Ä°spanyolca", "Japonca", "TÃ¼rkÃ§e"]
        )
        
        if st.button("Ã‡evir", type="primary"):
            if translate_input:
                with st.spinner("Ã‡eviri yapÄ±lÄ±yor..."):
                    translation = get_openai_response(
                        translate_input,
                        f"Sen bir Ã§evirmensin. Verilen metni {target_language} diline Ã§evir.",
                        model=model_choice
                    )
                    st.session_state.translation_result = translation
                    st.success("Ã‡eviri tamamlandÄ±!")
        
        if st.session_state.translation_result:
            st.text_area("Ã‡eviri:", value=st.session_state.translation_result, height=150)

# ============================================================================
# TAB 4: Kod AÃ§Ä±klama
# ============================================================================

with tab4:
    st.header("ğŸ’» Kod AÃ§Ä±klama")
    st.markdown("### Kod aÃ§Ä±klama aracÄ±")
    
    code_language = st.selectbox(
        "Programlama Dili:",
        ["Python", "JavaScript", "Java", "C++", "Go", "Rust"],
        index=0
    )
    
    code_input = st.text_area(
        "AÃ§Ä±klamak istediÄŸiniz kodu yazÄ±n:",
        height=300,
        placeholder=f"# {code_language} kodunuzu buraya yazÄ±n..."
    )
    
    if st.button("AÃ§Ä±kla", type="primary"):
        if code_input:
            with st.spinner("Kod aÃ§Ä±klamasÄ± oluÅŸturuluyor..."):
                explanation = get_openai_response(
                    f"Bu kodu aÃ§Ä±kla:\n\n```{code_language.lower()}\n{code_input}\n```",
                    f"Sen bir {code_language} programlama uzmanÄ±sÄ±n. Verilen kodu detaylÄ± ÅŸekilde aÃ§Ä±kla.",
                    model=model_choice
                )
                st.success("AÃ§Ä±klama oluÅŸturuldu!")
                st.markdown("### ğŸ“– AÃ§Ä±klama:")
                st.markdown(explanation)
        else:
            st.warning("LÃ¼tfen kod girin!")

# ============================================================================
# TAB 5: Veri GÃ¶rselleÅŸtirme
# ============================================================================

with tab5:
    st.header("ğŸ“Š Veri GÃ¶rselleÅŸtirme")
    st.markdown("### LLM ile veri analizi ve gÃ¶rselleÅŸtirme")
    
    # Ã–rnek veri oluÅŸtur
    sample_data = {
        "ÃœrÃ¼n": ["A", "B", "C", "D", "E"],
        "SatÄ±ÅŸ": [100, 150, 200, 120, 180],
        "Kategori": ["Elektronik", "Giyim", "Elektronik", "Giyim", "Elektronik"]
    }
    df = pd.DataFrame(sample_data)
    
    st.subheader("Ã–rnek Veri")
    st.dataframe(df, width='stretch')
    
    # Veri analizi iÃ§in prompt
    analysis_prompt = st.text_area(
        "Veri analizi iÃ§in soru sorun:",
        placeholder="Ã–rn: Bu verilerde hangi kategoride en Ã§ok satÄ±ÅŸ var?",
        height=100
    )
    
    if st.button("Analiz Et", type="primary"):
        if analysis_prompt:
            with st.spinner("Analiz yapÄ±lÄ±yor..."):
                # Veriyi string'e Ã§evir
                data_str = df.to_string()
                
                response = get_openai_response(
                    f"Bu veri tablosunu analiz et:\n\n{data_str}\n\nSoru: {analysis_prompt}",
                    "Sen bir veri analiz uzmanÄ±sÄ±n. Verilen veriyi analiz et ve yorum yap.",
                    model=model_choice
                )
                
                st.markdown("### ğŸ“Š Analiz Sonucu:")
                st.markdown(response)
                
                # GÃ¶rselleÅŸtirme
                st.markdown("### ğŸ“ˆ GÃ¶rselleÅŸtirme:")
                
                # Bar chart
                fig_bar = px.bar(df, x="ÃœrÃ¼n", y="SatÄ±ÅŸ", color="Kategori", title="ÃœrÃ¼n SatÄ±ÅŸlarÄ±")
                st.plotly_chart(fig_bar, use_columns_width=True)
                
                # Pie chart
                category_sales = df.groupby("Kategori")["SatÄ±ÅŸ"].sum().reset_index()
                fig_pie = px.pie(category_sales, values="SatÄ±ÅŸ", names="Kategori", title="Kategori BazÄ±nda SatÄ±ÅŸ DaÄŸÄ±lÄ±mÄ±")
                st.plotly_chart(fig_pie, use_columns_width=True)
        else:
            st.warning("LÃ¼tfen bir soru girin!")

# ============================================================================
# FOOTER
# ============================================================================

st.divider()
st.markdown(
    """
    ---
    **Not**: Bu uygulama OpenAI API kullanmaktadÄ±r. API key'inizi `.env` dosyasÄ±na eklemeyi unutmayÄ±n.
    """
)

