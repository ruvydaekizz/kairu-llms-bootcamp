"""
Gradio ile Frontend UygulamasÄ±
LLM tabanlÄ± chatbot ve Ã§eÅŸitli uygulamalar iÃ§in Gradio arayÃ¼zÃ¼
"""

import gradio as gr
from openai import OpenAI
import os
from dotenv import load_dotenv
import time

# Environment variables yÃ¼kle
load_dotenv()

# OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ============================================================================
# Ã–RNEK 1: Basit Chatbot ArayÃ¼zÃ¼
# ============================================================================

def simple_chatbot(message, history):
    """
    Basit chatbot fonksiyonu
    """
    try:
        # Convert history to OpenAI format
        messages = [{"role": "system", "content": "Sen yardÄ±mcÄ± bir asistansÄ±n. KÄ±sa ve net cevaplar ver."}]
        
        # Add conversation history if it exists
        if history:
            for msg in history:
                if isinstance(msg, dict) and "role" in msg and "content" in msg:
                    messages.append(msg)
                elif isinstance(msg, (list, tuple)) and len(msg) == 2:
                    # Handle old tuple format if any
                    messages.append({"role": "user", "content": msg[0]})
                    messages.append({"role": "assistant", "content": msg[1]})
        
        # Add current message
        messages.append({"role": "user", "content": message})
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=150,
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"


# ============================================================================
# Ã–RNEK 2: Streaming Output ile Chatbot
# ============================================================================

def streaming_chatbot(message, history):
    """
    Streaming output ile chatbot
    """
    try:
        # Convert history to OpenAI format
        messages = [{"role": "system", "content": "Sen yardÄ±mcÄ± bir asistansÄ±n."}]
        
        # Add conversation history if it exists
        if history:
            for msg in history:
                if isinstance(msg, dict) and "role" in msg and "content" in msg:
                    messages.append(msg)
                elif isinstance(msg, (list, tuple)) and len(msg) == 2:
                    # Handle old tuple format if any
                    messages.append({"role": "user", "content": msg[0]})
                    messages.append({"role": "assistant", "content": msg[1]})
        
        # Add current message
        messages.append({"role": "user", "content": message})
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            stream=True,
            max_tokens=200,
            temperature=0.7
        )
        
        full_response = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                yield full_response
    except Exception as e:
        yield f"Hata oluÅŸtu: {str(e)}"


# ============================================================================
# Ã–RNEK 3: Metin Ä°ÅŸleme UygulamasÄ±
# ============================================================================

def text_summarizer(text):
    """
    Metin Ã¶zetleme fonksiyonu
    """
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sen bir metin Ã¶zetleme uzmanÄ±sÄ±n. Verilen metni kÄ±sa ve Ã¶z ÅŸekilde Ã¶zetle."},
                {"role": "user", "content": f"Bu metni Ã¶zetle:\n\n{text}"}
            ],
            max_tokens=150,
            temperature=0.5
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"


def text_translator(text, target_language):
    """
    Metin Ã§eviri fonksiyonu
    """
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"Sen bir Ã§evirmensin. Verilen metni {target_language} diline Ã§evir."},
                {"role": "user", "content": text}
            ],
            max_tokens=200,
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"


# ============================================================================
# Ã–RNEK 4: Multi-Input UygulamasÄ±
# ============================================================================

def code_explainer(code, language):
    """
    Kod aÃ§Ä±klama fonksiyonu
    """
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"Sen bir {language} programlama uzmanÄ±sÄ±n. Verilen kodu detaylÄ± ÅŸekilde aÃ§Ä±kla."},
                {"role": "user", "content": f"Bu kodu aÃ§Ä±kla:\n\n```{language}\n{code}\n```"}
            ],
            max_tokens=300,
            temperature=0.5
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"


# ============================================================================
# Ã–RNEK 5: Dosya YÃ¼kleme ve Ä°ÅŸleme
# ============================================================================

def file_processor(file):
    """
    Dosya iÃ§eriÄŸini iÅŸleme (PDF, metin dosyalarÄ± vb.)
    """
    if file is None:
        return "LÃ¼tfen bir dosya yÃ¼kleyin."
    
    try:
        # Dosya yolunu al
        file_path = file.name if hasattr(file, 'name') else file
        
        # Dosya adÄ±nÄ± ve uzantÄ±sÄ±nÄ± al
        import os
        filename = os.path.basename(file_path)
        file_extension = os.path.splitext(filename)[1].lower()
        
        content = ""
        
        # PDF dosyalarÄ± iÃ§in
        if file_extension == '.pdf':
            try:
                import pdfplumber
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages[:5]:  # Ä°lk 5 sayfa
                        page_text = page.extract_text()
                        if page_text:
                            content += page_text + "\n\n"
                
                if not content:
                    # Alternatif olarak PyPDF2 dene
                    import PyPDF2
                    with open(file_path, 'rb') as f:
                        pdf_reader = PyPDF2.PdfReader(f)
                        for page_num in range(min(5, len(pdf_reader.pages))):
                            page = pdf_reader.pages[page_num]
                            content += page.extract_text() + "\n\n"
                            
            except Exception as pdf_error:
                return f"PDF okuma hatasÄ±: {str(pdf_error)}"
        
        # Metin dosyalarÄ± iÃ§in
        else:
            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
        
        if not content:
            return "Dosya okunamadÄ±. Desteklenmeyen format veya karakter kodlamasÄ±."
        
        # Ä°lk 2000 karakteri al (API limiti iÃ§in)
        content_preview = content[:2000]
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sen bir dosya analiz uzmanÄ±sÄ±n. Verilen dosya iÃ§eriÄŸini analiz et, Ã¶zetini Ã§Ä±kar ve ana konularÄ± belirt."},
                {"role": "user", "content": f"Dosya adÄ±: {filename}\nDosya tipi: {file_extension}\n\nDosya iÃ§eriÄŸini analiz et:\n\n{content_preview}"}
            ],
            max_tokens=400,
            temperature=0.5
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"


# ============================================================================
# GRADIO ARAYÃœZÃœ OLUÅTURMA
# ============================================================================

def create_gradio_interface():
    """
    Gradio arayÃ¼zÃ¼nÃ¼ oluÅŸtur
    """
    
    # Tema ve stil ayarlarÄ±
    theme = gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="gray",
        font=("Arial", "sans-serif")
    )
    
    with gr.Blocks(theme=theme, title="LLM Uygulama Demo") as demo:
        gr.Markdown(
            """
            # ğŸ¤– LLM TabanlÄ± Uygulama Ã–rnekleri
            
            Bu uygulama Gradio kullanarak Ã§eÅŸitli LLM uygulamalarÄ±nÄ± gÃ¶sterir.
            """
        )
        
        # Tab yapÄ±sÄ±
        with gr.Tabs():
            # TAB 1: Basit Chatbot
            with gr.Tab("ğŸ’¬ Basit Chatbot"):
                gr.Markdown("### Basit chatbot arayÃ¼zÃ¼")
                chatbot = gr.Chatbot(label="KonuÅŸma", type="messages")
                msg = gr.Textbox(
                    label="MesajÄ±nÄ±z",
                    placeholder="MesajÄ±nÄ±zÄ± yazÄ±n...",
                    lines=2
                )
                submit_btn = gr.Button("GÃ¶nder", variant="primary")
                clear_btn = gr.Button("Temizle")
                
                def respond(message, chat_history):
                    bot_message = simple_chatbot(message, chat_history)
                    chat_history.append({"role": "user", "content": message})
                    chat_history.append({"role": "assistant", "content": bot_message})
                    return "", chat_history
                
                msg.submit(respond, [msg, chatbot], [msg, chatbot])
                submit_btn.click(respond, [msg, chatbot], [msg, chatbot])
                clear_btn.click(lambda: [], None, chatbot, queue=False)
            
            # TAB 2: Streaming Chatbot
            with gr.Tab("ğŸŒŠ Streaming Chatbot"):
                gr.Markdown("### Streaming output ile chatbot")
                streaming_chatbot_ui = gr.Chatbot(label="KonuÅŸma", type="messages")
                streaming_msg = gr.Textbox(
                    label="MesajÄ±nÄ±z",
                    placeholder="MesajÄ±nÄ±zÄ± yazÄ±n...",
                    lines=2
                )
                streaming_submit = gr.Button("GÃ¶nder", variant="primary")
                streaming_clear = gr.Button("Temizle")
                
                def streaming_respond(message, chat_history):
                    chat_history.append({"role": "user", "content": message})
                    chat_history.append({"role": "assistant", "content": ""})
                    for response in streaming_chatbot(message, chat_history[:-2]):  # Exclude the current exchange
                        chat_history[-1] = {"role": "assistant", "content": response}
                        yield chat_history
                
                streaming_msg.submit(streaming_respond, [streaming_msg, streaming_chatbot_ui], streaming_chatbot_ui)
                streaming_submit.click(streaming_respond, [streaming_msg, streaming_chatbot_ui], streaming_chatbot_ui)
                streaming_clear.click(lambda: [], None, streaming_chatbot_ui, queue=False)
            
            # TAB 3: Metin Ä°ÅŸleme
            with gr.Tab("ğŸ“ Metin Ä°ÅŸleme"):
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("### Metin Ã–zetleme")
                        text_input = gr.Textbox(
                            label="Metin",
                            placeholder="Ã–zetlemek istediÄŸiniz metni yazÄ±n...",
                            lines=5
                        )
                        summarize_btn = gr.Button("Ã–zetle", variant="primary")
                        summary_output = gr.Textbox(label="Ã–zet", lines=5)
                        
                        summarize_btn.click(text_summarizer, text_input, summary_output)
                    
                    with gr.Column():
                        gr.Markdown("### Metin Ã‡eviri")
                        translate_input = gr.Textbox(
                            label="Ã‡evrilecek Metin",
                            placeholder="Ã‡evirmek istediÄŸiniz metni yazÄ±n...",
                            lines=3
                        )
                        language_select = gr.Dropdown(
                            choices=["Ä°ngilizce", "FransÄ±zca", "Almanca", "Ä°spanyolca", "Japonca"],
                            label="Hedef Dil",
                            value="Ä°ngilizce"
                        )
                        translate_btn = gr.Button("Ã‡evir", variant="primary")
                        translate_output = gr.Textbox(label="Ã‡eviri", lines=5)
                        
                        translate_btn.click(text_translator, [translate_input, language_select], translate_output)
            
            # TAB 4: Kod AÃ§Ä±klama
            with gr.Tab("ğŸ’» Kod AÃ§Ä±klama"):
                gr.Markdown("### Kod aÃ§Ä±klama aracÄ±")
                code_input = gr.Code(
                    label="Kod",
                    language="python"
                )
                code_language = gr.Dropdown(
                    choices=["Python", "JavaScript", "Java", "C++", "Go"],
                    label="Programlama Dili",
                    value="Python"
                )
                explain_btn = gr.Button("AÃ§Ä±kla", variant="primary")
                code_explanation = gr.Textbox(label="AÃ§Ä±klama", lines=10)
                
                explain_btn.click(code_explainer, [code_input, code_language], code_explanation)
            
            # TAB 5: Dosya Ä°ÅŸleme
            with gr.Tab("ğŸ“ Dosya Ä°ÅŸleme"):
                gr.Markdown("### Dosya iÃ§eriÄŸi analizi\nDesteklenen formatlar: PDF, TXT, Python, JavaScript, Markdown, JSON, CSV, HTML, CSS, YAML, XML")
                file_input = gr.File(
                    label="Dosya YÃ¼kle",
                    file_types=[".txt", ".py", ".js", ".md", ".json", ".csv", ".html", ".css", ".yaml", ".yml", ".xml", ".pdf"]
                )
                process_btn = gr.Button("Ä°ÅŸle", variant="primary")
                file_output = gr.Textbox(label="Analiz Sonucu", lines=10)
                
                process_btn.click(file_processor, file_input, file_output)
        
        # Footer
        gr.Markdown(
            """
            ---
            **Not**: Bu uygulama OpenAI API kullanmaktadÄ±r. API key'inizi `.env` dosyasÄ±na eklemeyi unutmayÄ±n.
            """
        )
    
    return demo


# ============================================================================
# UYGULAMA Ã‡ALIÅTIRMA
# ============================================================================

if __name__ == "__main__":
    demo = create_gradio_interface()
    
    # Queue kullanarak rate limiting
    demo.queue()
    
    # UygulamayÄ± baÅŸlat
    demo.launch(
        server_name="0.0.0.0",  # TÃ¼m network interface'lerde dinle
        server_port=7861,        # Port numarasÄ±
        share=False,             # Public link oluÅŸturma
        show_error=True          # HatalarÄ± gÃ¶ster
    )

