"""
Basit TÃ¼rkÃ§e LLM Ã–rneÄŸi
"""

from transformers import pipeline

# TÃ¼rkÃ§e destekli model
MODEL_ID = "Qwen/Qwen2.5-1.5B-Instruct"

print("ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e LLM yÃ¼kleniyor...")

# Pipeline oluÅŸtur
generator = pipeline(
    "text-generation",
    model=MODEL_ID,
    max_new_tokens=100,
    temperature=0.3
)

# TÃ¼rkÃ§e sorular - basit ve net
questions = [
    "Merhaba",
    "2+2 kaÃ§ eder?",
    "Python nedir?", 
    "Yapay zeka nasÄ±l Ã§alÄ±ÅŸÄ±r?"
]

print("âœ… Model hazÄ±r! TÃ¼rkÃ§e sorular test ediliyor...\n")

for i, question in enumerate(questions, 1):
    print(f"ğŸ”¤ Soru {i}: {question}")
    
    # Qwen iÃ§in chat formatÄ±
    prompt = f"<|im_start|>user\n{question}<|im_end|>\n<|im_start|>assistant\n"
    
    try:
        response = generator(prompt)
        full_text = response[0]["generated_text"]
        
        # Sadece assistant cevabÄ±nÄ± al
        if "<|im_start|>assistant\n" in full_text:
            answer = full_text.split("<|im_start|>assistant\n")[-1]
            answer = answer.split("<|im_end|>")[0].strip()
            print(f"ğŸ¤– Cevap: {answer}")
        else:
            print(f"ğŸ¤– Cevap: {full_text}")
            
    except Exception as e:
        print(f"âŒ Hata: {e}")
    
    print("-" * 60)

print("\nğŸ‰ Test tamamlandÄ±!")