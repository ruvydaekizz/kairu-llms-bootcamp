"""
Hafta 5 - BÃ¶lÃ¼m 5: Streaming Output ve CanlÄ± Veri AkÄ±ÅŸÄ±
LangChain ile streaming ve real-time uygulamalar
"""

import os
import time
import asyncio
from typing import Any, Dict, List, Optional
from langchain_openai import OpenAI
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import LLMResult
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.agents import AgentExecutor, Tool, initialize_agent, AgentType
from langchain.memory import ConversationBufferMemory

from dotenv import load_dotenv
load_dotenv()

# =============================================================================
# Ã–ZEL CALLBACK HANDLER'LAR
# =============================================================================

class CustomStreamingHandler(BaseCallbackHandler):
    """Ã–zel streaming handler"""
    
    def __init__(self):
        self.tokens = []
        self.current_response = ""
    
    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> Any:
        """LLM baÅŸladÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lÄ±r"""
        print("ğŸ¤– AI yanÄ±t oluÅŸturuyor...\n")
        print("ğŸ“ CanlÄ± YanÄ±t: ", end="", flush=True)
    
    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:
        """Her yeni token geldiÄŸinde Ã§aÄŸrÄ±lÄ±r"""
        print(token, end="", flush=True)
        self.tokens.append(token)
        self.current_response += token
        time.sleep(0.05)  # Typing efekti iÃ§in
    
    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> Any:
        """LLM bittiÄŸinde Ã§aÄŸrÄ±lÄ±r"""
        print("\n\nâœ… YanÄ±t tamamlandÄ±!")
        print(f"ğŸ“Š Toplam token sayÄ±sÄ±: {len(self.tokens)}")
    
    def on_llm_error(self, error: Exception, **kwargs: Any) -> Any:
        """Hata oluÅŸtuÄŸunda Ã§aÄŸrÄ±lÄ±r"""
        print(f"\nâŒ Hata: {error}")

class ProgressHandler(BaseCallbackHandler):
    """Ä°lerleme gÃ¶sterici handler"""
    
    def __init__(self):
        self.step_count = 0
        self.steps = ["ğŸ” Analiz", "ğŸ’­ DÃ¼ÅŸÃ¼nme", "âœï¸ Yazma", "ğŸ¯ Tamamlama"]
    
    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> Any:
        print("ğŸ“ˆ Ä°ÅŸlem BaÅŸlÄ±yor:")
        self.show_progress()
    
    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:
        if len(token.strip()) > 0 and self.step_count < len(self.steps) - 1:
            if token in ['.', '!', '?', '\n']:
                self.step_count += 1
                self.show_progress()
    
    def show_progress(self):
        """Ä°lerleme Ã§ubuÄŸunu gÃ¶ster"""
        progress = "["
        for i, step in enumerate(self.steps):
            if i <= self.step_count:
                progress += f"âœ… {step} "
            else:
                progress += f"â³ {step} "
        progress += "]"
        print(f"\r{progress}", end="", flush=True)
    
    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> Any:
        self.step_count = len(self.steps) - 1
        self.show_progress()
        print("\nğŸ‰ Ä°ÅŸlem TamamlandÄ±!\n")

# =============================================================================
# STREAMING Ã–RNEKLERÄ°
# =============================================================================

def basic_streaming_example():
    """Temel streaming Ã¶rneÄŸi"""
    print("=" * 60)
    print("1. TEMEL STREAMING OUTPUT")
    print("=" * 60)
    
    # Streaming handler ile LLM
    llm = OpenAI(
        temperature=0.7,
        streaming=True,
        callbacks=[StreamingStdOutCallbackHandler()]
    )
    
    print("Normal yanÄ±t (streaming yok):")
    normal_llm = OpenAI(temperature=0.7)
    normal_response = normal_llm("Python hakkÄ±nda kÄ±sa bir aÃ§Ä±klama yaz.")
    print(normal_response)
    
    print("\n" + "-" * 40)
    print("Streaming yanÄ±t:")
    streaming_response = llm("Python hakkÄ±nda kÄ±sa bir aÃ§Ä±klama yaz.")
    print("\n")
    
    return streaming_response

def custom_streaming_example():
    """Ã–zel streaming handler Ã¶rneÄŸi"""
    print("\n" + "=" * 60)
    print("2. Ã–ZEL STREAMING HANDLER")
    print("=" * 60)
    
    # Ã–zel handler ile LLM
    custom_handler = CustomStreamingHandler()
    llm = OpenAI(
        temperature=0.7,
        streaming=True,
        callbacks=[custom_handler]
    )
    
    # Uzun bir prompt ile test
    prompt = """
    Yapay zeka teknolojisinin gelecekte topluma etkilerini detaylÄ± olarak aÃ§Ä±kla.
    Pozitif ve negatif etkileri ayrÄ± ayrÄ± ele al.
    """
    
    response = llm(prompt)
    
    print(f"\nğŸ“‹ Handler Bilgileri:")
    print(f"- Toplanan token sayÄ±sÄ±: {len(custom_handler.tokens)}")
    print(f"- Ä°lk 5 token: {custom_handler.tokens[:5]}")
    print(f"- Son 5 token: {custom_handler.tokens[-5:]}")
    
    return custom_handler

def progress_streaming_example():
    """Ä°lerleme gÃ¶sterici ile streaming"""
    print("\n" + "=" * 60)
    print("3. Ä°LERLEME GÃ–STERÄ°CÄ°LÄ° STREAMING")
    print("=" * 60)
    
    progress_handler = ProgressHandler()
    llm = OpenAI(
        temperature=0.7,
        streaming=True,
        callbacks=[progress_handler]
    )
    
    prompt = """
    Bir startup'Ä±n baÅŸarÄ±lÄ± olmasÄ± iÃ§in gerekli 5 temel unsuru aÃ§Ä±kla.
    Her unsur iÃ§in detaylÄ± aÃ§Ä±klama yap.
    """
    
    response = llm(prompt)
    print(response)
    
    return progress_handler

# =============================================================================
# STREAMING CHAIN Ã–RNEKLERÄ°
# =============================================================================

def streaming_chain_example():
    """Chain ile streaming"""
    print("\n" + "=" * 60)
    print("4. STREAMING CHAIN KULLANIMI")
    print("=" * 60)
    
    # Streaming LLM
    streaming_llm = OpenAI(
        temperature=0.7,
        streaming=True,
        callbacks=[CustomStreamingHandler()]
    )
    
    # Prompt template
    prompt = PromptTemplate(
        input_variables=["topic"],
        template="""
        Bu konu hakkÄ±nda yaratÄ±cÄ± bir hikaye yaz: {topic}
        Hikaye en az 200 kelime olsun ve heyecanlÄ± detaylar iÃ§ersin.
        """
    )
    
    # Chain oluÅŸtur
    chain = LLMChain(
        llm=streaming_llm,
        prompt=prompt
    )
    
    # Chain'i Ã§alÄ±ÅŸtÄ±r
    print("Hikaye konusu: 'Uzayda kaybolmuÅŸ bir robot'")
    result = chain.run("uzayda kaybolmuÅŸ bir robot")
    
    return result

# =============================================================================
# REAL-TIME SOHBET SÄ°MÃœLASYONU
# =============================================================================

class RealTimeChatBot:
    def __init__(self):
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        self.streaming_handler = CustomStreamingHandler()
        
        self.llm = OpenAI(
            temperature=0.8,
            streaming=True,
            callbacks=[self.streaming_handler]
        )
        
        self.prompt = PromptTemplate(
            input_variables=["chat_history", "user_input"],
            template="""
            Sen arkadaÅŸ canlÄ±sÄ± bir sohbet botusun. KullanÄ±cÄ±yla doÄŸal bir sohbet et.
            
            Ã–nceki konuÅŸma:
            {chat_history}
            
            KullanÄ±cÄ±: {user_input}
            
            Bot:
            """
        )
        
        self.chain = LLMChain(
            llm=self.llm,
            prompt=self.prompt,
            memory=self.memory
        )
    
    def chat(self, user_input: str):
        """KullanÄ±cÄ± giriÅŸini iÅŸle"""
        print(f"\nğŸ‘¤ KullanÄ±cÄ±: {user_input}")
        
        # Typing indicator
        print("âŒ¨ï¸  Bot yazÄ±yor", end="", flush=True)
        for i in range(3):
            time.sleep(0.5)
            print(".", end="", flush=True)
        print("\n")
        
        # Streaming response
        response = self.chain.run(user_input=user_input)
        return response

def realtime_chat_example():
    """Real-time sohbet Ã¶rneÄŸi"""
    print("\n" + "=" * 60)
    print("5. REAL-TIME SOHBET BOT'U")
    print("=" * 60)
    
    chatbot = RealTimeChatBot()
    
    # SimÃ¼le edilmiÅŸ sohbet
    conversation = [
        "Merhaba! NasÄ±lsÄ±n?",
        "BugÃ¼n hava Ã§ok gÃ¼zel, sen ne yapÄ±yorsun?",
        "Yapay zeka hakkÄ±nda ne dÃ¼ÅŸÃ¼nÃ¼yorsun?",
        "Bana bir ÅŸaka anlatÄ±r mÄ±sÄ±n?"
    ]
    
    for message in conversation:
        try:
            response = chatbot.chat(message)
            time.sleep(1)  # Sohbet aralÄ±ÄŸÄ±
        except Exception as e:
            print(f"Sohbet hatasÄ±: {e}")
            break
    
    return chatbot

# =============================================================================
# ASYNC STREAMING Ã–RNEKLERÄ°
# =============================================================================

async def async_streaming_example():
    """Asynchronous streaming Ã¶rneÄŸi"""
    print("\n" + "=" * 60)
    print("6. ASYNC STREAMING (SimÃ¼le EdilmiÅŸ)")
    print("=" * 60)
    
    # Async streaming simÃ¼lasyonu
    responses = [
        "Python Ã§ok gÃ¼Ã§lÃ¼ bir programlama dilidir.",
        "Web geliÅŸtirme, veri analizi, yapay zeka alanlarÄ±nda kullanÄ±lÄ±r.",
        "SÃ¶z dizimi basit ve okunabilir olduÄŸu iÃ§in Ã¶ÄŸrenmesi kolaydÄ±r.",
        "GeniÅŸ kÃ¼tÃ¼phane ekosistemi sayesinde hÄ±zlÄ± geliÅŸtirme saÄŸlar."
    ]
    
    print("ğŸš€ Async streaming baÅŸlÄ±yor...\n")
    
    for i, response in enumerate(responses, 1):
        print(f"ğŸ“¦ Chunk {i}: ", end="", flush=True)
        
        # Her karakteri ayrÄ± ayrÄ± yazdÄ±r
        for char in response:
            print(char, end="", flush=True)
            await asyncio.sleep(0.03)
        
        print()  # Yeni satÄ±r
        await asyncio.sleep(0.5)  # Chunk arasÄ± bekleme
    
    print("\nâœ… Async streaming tamamlandÄ±!")

# =============================================================================
# PERFORMANS KARÅILAÅTIRMASI
# =============================================================================

def streaming_performance_comparison():
    """Streaming vs Normal performans karÅŸÄ±laÅŸtÄ±rmasÄ±"""
    print("\n" + "=" * 60)
    print("7. PERFORMANS KARÅILAÅTIRMASI")
    print("=" * 60)
    
    prompt = "Python programlama dilinin avantajlarÄ±nÄ± listele ve aÃ§Ä±kla."
    
    # Normal LLM - zaman Ã¶lÃ§
    print("â±ï¸  Normal LLM testi...")
    normal_llm = OpenAI(temperature=0.7)
    start_time = time.time()
    normal_response = normal_llm(prompt)
    normal_time = time.time() - start_time
    
    print(f"Normal LLM sÃ¼resi: {normal_time:.2f} saniye")
    print(f"Normal yanÄ±t uzunluÄŸu: {len(normal_response)} karakter\n")
    
    # Streaming LLM - zaman Ã¶lÃ§  
    print("â±ï¸  Streaming LLM testi...")
    streaming_llm = OpenAI(
        temperature=0.7,
        streaming=True,
        callbacks=[StreamingStdOutCallbackHandler()]
    )
    start_time = time.time()
    streaming_response = streaming_llm(prompt)
    streaming_time = time.time() - start_time
    
    print(f"\nStreaming LLM sÃ¼resi: {streaming_time:.2f} saniye")
    print(f"Streaming yanÄ±t uzunluÄŸu: {len(streaming_response)} karakter")
    
    print(f"\nğŸ“Š Analiz:")
    print(f"- SÃ¼re farkÄ±: {abs(normal_time - streaming_time):.2f} saniye")
    print(f"- Streaming kullanÄ±cÄ± deneyimi: Daha iyi (canlÄ± feedback)")
    print(f"- Normal LLM: Daha hÄ±zlÄ± iÅŸlem (tek seferde)")

# =============================================================================
# ANA FONKSÄ°YON
# =============================================================================

def main():
    print("LANGCHAIN STREAMING VE CANLI VERÄ° AKIÅI Ã–RNEKLERÄ°")
    print("Bu Ã¶rneklerde streaming output ve real-time uygulamalarÄ± Ã¶ÄŸreneceksiniz.\n")
    
    try:
        # Streaming Ã¶rneklerini Ã§alÄ±ÅŸtÄ±r
        basic_streaming_example()
        custom_streaming_example()
        progress_streaming_example()
        streaming_chain_example()
        realtime_chat_example()
        
        # Async Ã¶rneÄŸi Ã§alÄ±ÅŸtÄ±r
        asyncio.run(async_streaming_example())
        
        streaming_performance_comparison()
        
        print("\n" + "=" * 60)
        print("TÃœM STREAMING Ã–RNEKLERÄ° TAMAMLANDI!")
        print("ArtÄ±k kendi real-time uygulamalarÄ±nÄ±zÄ± geliÅŸtirebilirsiniz.")
        print("=" * 60)
        
        # Pratik ipuÃ§larÄ±
        print("\nğŸ¯ STREAMING Ä°PUÃ‡LARI:")
        print("1. Uzun yanÄ±tlar iÃ§in streaming kullanÄ±n")
        print("2. KullanÄ±cÄ± deneyimini iyileÅŸtirir")
        print("3. Custom handler'lar ile Ã¶zelleÅŸtirin")
        print("4. Progress indicator'lar ekleyin")
        print("5. Error handling'i unutmayÄ±n")
        
    except Exception as e:
        print(f"Genel hata: {e}")
        print("OpenAI API anahtarÄ±nÄ±zÄ± kontrol edin!")

if __name__ == "__main__":
    main()